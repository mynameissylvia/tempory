{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_order(open_csv):\n",
    "    data = pd.read_csv(open_csv)\n",
    "    c = list(data).copy()\n",
    "    label = []\n",
    "    shape = []\n",
    "    for i in range(len(data)):\n",
    "        label.append(int(data[c[0]][i]))\n",
    "        feature = np.fromstring(data[c[1]][i], dtype=int, sep=' ')\n",
    "        shape.append(np.reshape(feature,(48,48)))\n",
    "    y = np.asarray(label)\n",
    "    x = np.asarray(shape)\n",
    "    return y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = sys.argv[1]\n",
    "#test = sys.argv[2]\n",
    "#sample = sys.argv[3]\n",
    "train = 'train.csv'\n",
    "order = read_and_order(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extant(a,n,length = 40):\n",
    "    m = []\n",
    "    l = len(a)\n",
    "    c = 1.0*l/n\n",
    "    original_l = int((l-length)/2)\n",
    "    size_l = int((n-length)/2)\n",
    "    count = 0\n",
    "    for j in a:\n",
    "        m1 =[]\n",
    "        for k in range(n-1):\n",
    "            current_n = k*c\n",
    "            position = int(current_n)\n",
    "            adding = current_n-position\n",
    "            element = j[position]+j[position+1]*adding\n",
    "            m1.append(element)\n",
    "        m1.append(j[-1])\n",
    "        if len(a)-count >original_l and count >=original_l:\n",
    "            if size_l >0:\n",
    "                m.append(m1[size_l:-1*size_l])\n",
    "            else:\n",
    "                m.append(m1)\n",
    "        count+=1\n",
    "    return m\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = order[0]\n",
    "x_train = order[1]\n",
    "x_train = x_train.reshape(x_train.shape[0],48,48,1).astype('float32')/255\n",
    "y_train= np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change to 40*40 ,added\n",
    "x_train_m = order[1].reshape(order[1].shape[0],48,48).astype('float32')/255\n",
    "x_train_mirrow = []\n",
    "for i in x_train_m:\n",
    "    a = i.tolist()\n",
    "    new_m_1 = []  #DOWN RIGHT\n",
    "    new_m_2 = []  #DOWN left\n",
    "    new_m_3 = []  #UP RIGHT\n",
    "    new_m_4 = []  #UP LEFT\n",
    "    new_m_5 = []  #MIDDLE\n",
    "    \n",
    "    \n",
    "    #REVERSE\n",
    "    new_m_11 = [] \n",
    "    new_m_21 = []\n",
    "    new_m_31 = []\n",
    "    new_m_41 = []\n",
    "    new_m_51 = []\n",
    "    \n",
    "    r = []\n",
    "    count = 0\n",
    "    for j in a:\n",
    "        m = j.copy()\n",
    "        n = j.copy()\n",
    "        m.reverse()\n",
    "        r.append(m)\n",
    "        if count >=6:\n",
    "            new_m_1.append(n[6:])\n",
    "            new_m_11.append(m[6:])\n",
    "            new_m_2.append(n[:-6])\n",
    "            new_m_21.append(m[:-6])\n",
    "        if len(a)-count >6:\n",
    "            new_m_3.append(n[6:])\n",
    "            new_m_31.append(m[6:])\n",
    "            new_m_4.append(n[:-6])\n",
    "            new_m_41.append(m[:-6])\n",
    "        if len(a)-count >3 and count >=3:\n",
    "            new_m_5.append(n[3:-3])\n",
    "            new_m_51.append(m[3:-3])\n",
    "        count+=1\n",
    "    #add some extension\n",
    "    x_train_mirrow.append(new_m_1)\n",
    "    x_train_mirrow.append(new_m_2)\n",
    "    x_train_mirrow.append(new_m_3)\n",
    "    x_train_mirrow.append(new_m_4)\n",
    "    x_train_mirrow.append(new_m_5)\n",
    "    x_train_mirrow.append(new_m_11)\n",
    "    x_train_mirrow.append(new_m_21)\n",
    "    x_train_mirrow.append(new_m_31)\n",
    "    x_train_mirrow.append(new_m_41)\n",
    "    x_train_mirrow.append(new_m_51)\n",
    "#    x_train_mirrow.append(extant(a,40))\n",
    "#    x_train_mirrow.append(extant(r,40))\n",
    "x_train_m = np.array(x_train_mirrow, dtype=np.float32)\n",
    "x_train_m = x_train_m.reshape(x_train_m.shape[0],42,42,1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = order[0]\n",
    "y_train_m = [val for val in y_train.tolist() for _ in (0,1,2,3,4,5,6,7,8,9)]\n",
    "y_train_m = np.array(y_train_m, dtype=np.float32)\n",
    "y_train_m= np_utils.to_categorical(y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((287090, 7), (287090, 42, 42, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_m.shape,x_train_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Train on 229672 samples, validate on 57418 samples\n",
      "Epoch 1/30\n",
      " - 319s - loss: 1.4420 - acc: 0.4399 - val_loss: 1.2447 - val_acc: 0.5237\n",
      "Epoch 2/30\n",
      " - 317s - loss: 1.2133 - acc: 0.5373 - val_loss: 1.1520 - val_acc: 0.5675\n",
      "Epoch 3/30\n",
      " - 317s - loss: 1.1229 - acc: 0.5743 - val_loss: 1.1158 - val_acc: 0.5784\n",
      "Epoch 4/30\n",
      " - 318s - loss: 1.0528 - acc: 0.6027 - val_loss: 1.0928 - val_acc: 0.5897\n",
      "Epoch 5/30\n",
      " - 319s - loss: 0.9943 - acc: 0.6254 - val_loss: 1.0950 - val_acc: 0.5913\n",
      "Epoch 6/30\n",
      " - 317s - loss: 0.9431 - acc: 0.6456 - val_loss: 1.0766 - val_acc: 0.6010\n",
      "Epoch 7/30\n",
      " - 318s - loss: 0.8955 - acc: 0.6639 - val_loss: 1.0863 - val_acc: 0.5969\n",
      "Epoch 8/30\n",
      " - 318s - loss: 0.8518 - acc: 0.6812 - val_loss: 1.0888 - val_acc: 0.6016\n",
      "Epoch 9/30\n",
      " - 319s - loss: 0.8169 - acc: 0.6950 - val_loss: 1.0887 - val_acc: 0.6088\n",
      "Epoch 10/30\n",
      " - 319s - loss: 0.7839 - acc: 0.7079 - val_loss: 1.1004 - val_acc: 0.6032\n",
      "Epoch 11/30\n",
      " - 319s - loss: 0.7539 - acc: 0.7190 - val_loss: 1.1033 - val_acc: 0.6056\n",
      "Epoch 12/30\n",
      " - 321s - loss: 0.7319 - acc: 0.7276 - val_loss: 1.1161 - val_acc: 0.6032\n",
      "Epoch 13/30\n",
      " - 320s - loss: 0.7049 - acc: 0.7376 - val_loss: 1.1335 - val_acc: 0.6027\n",
      "Epoch 14/30\n",
      " - 319s - loss: 0.6849 - acc: 0.7464 - val_loss: 1.1534 - val_acc: 0.5967\n",
      "Epoch 15/30\n",
      " - 319s - loss: 0.6657 - acc: 0.7526 - val_loss: 1.1421 - val_acc: 0.6055\n",
      "Epoch 16/30\n",
      " - 318s - loss: 0.6518 - acc: 0.7581 - val_loss: 1.1420 - val_acc: 0.6050\n",
      "Epoch 17/30\n",
      " - 319s - loss: 0.6353 - acc: 0.7636 - val_loss: 1.1670 - val_acc: 0.6091\n",
      "Epoch 18/30\n",
      " - 318s - loss: 0.6186 - acc: 0.7718 - val_loss: 1.1690 - val_acc: 0.6087\n",
      "Epoch 19/30\n",
      " - 319s - loss: 0.6064 - acc: 0.7754 - val_loss: 1.1772 - val_acc: 0.6045\n",
      "Epoch 20/30\n",
      " - 319s - loss: 0.5958 - acc: 0.7804 - val_loss: 1.1802 - val_acc: 0.6101\n",
      "Epoch 21/30\n",
      " - 319s - loss: 0.5794 - acc: 0.7869 - val_loss: 1.2001 - val_acc: 0.6034\n",
      "Epoch 22/30\n",
      " - 320s - loss: 0.5701 - acc: 0.7900 - val_loss: 1.1877 - val_acc: 0.6046\n",
      "Epoch 23/30\n",
      " - 320s - loss: 0.5611 - acc: 0.7924 - val_loss: 1.2130 - val_acc: 0.6030\n",
      "Epoch 24/30\n",
      " - 319s - loss: 0.5540 - acc: 0.7951 - val_loss: 1.2191 - val_acc: 0.6049\n",
      "Epoch 25/30\n",
      " - 320s - loss: 0.5431 - acc: 0.7998 - val_loss: 1.2195 - val_acc: 0.6054\n",
      "Epoch 26/30\n",
      " - 320s - loss: 0.5321 - acc: 0.8039 - val_loss: 1.2361 - val_acc: 0.6013\n",
      "Epoch 27/30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'same',\n",
    "                 input_shape =(42,42,1),\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D((4,4)))  \n",
    "model.add(Conv2D(filters = 64,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'same',\n",
    "                 activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training ------------')\n",
    "training = model.fit(x_train_m, y_train_m,validation_split = 0.2, epochs=30, batch_size=128,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'test.csv'\n",
    "testing = read_and_order(test)\n",
    "x_test = testing[1].reshape(testing[1].shape[0],48,48).astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_m = []\n",
    "for i in x_test:\n",
    "    a = i.tolist()\n",
    "    new_m_t = []\n",
    "    count = 0\n",
    "    for j in a:\n",
    "        m = j.copy()\n",
    "        if len(a)-count >3 and count >=3:\n",
    "            new_m_t.append(m[3:-3])\n",
    "        count+=1\n",
    "    x_test_m.append(new_m_t)\n",
    "x_test_m = np.array(x_test_m, dtype=np.float32)\n",
    "x_test_m = x_test_m.reshape(x_test_m.shape[0],42,42,1).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict_classes(x_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = range(len(prediction))\n",
    "outcome = {\"id\":id_name,\n",
    "           \"label\":prediction}\n",
    "out = pd.DataFrame(outcome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 'sample.csv'\n",
    "out.to_csv(sample,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.654 filters = 20 kernel_size = (5,5) epochs = 30\n",
    "#0.615 filters = 16 kernel_size = (5,5) epochs = 30\n",
    "#0.667 filters = 32,kernel_size = (4,4),epochs = 30\n",
    "#0.702 filters = 32,kernel_size = (5,5),epochs = 30\n",
    "#0.649 filters = 32,kernel_size = (6,6),epochs = 20\n",
    "#0.729 filters = 32,kernel_size = (6,6),epochs = 30\n",
    "#0.739 filters = 48,kernel_size = (5,5),epochs = 30 batch_size=300\n",
    "# filters = 64,kernel_size = (5,5),epochs = 30 batch_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('current_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
